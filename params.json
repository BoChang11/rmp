{
  "name": "Motion Planning - Reeds-Shepp Car",
  "tagline": "By Sampling Based Methods(RRT & RRT*)",
  "body": "# Path Planning for Reeds-Shepp Car\r\n\r\n## Table of Contents\r\n - [Introduction](#introduction)\r\n - [Model Description](#model-description)\r\n - [Limitations](#limitations)\r\n - [Collision Detection](#collision-detection)\r\n - [Path Planning Techniques](#path-planning-techniques)\r\n    - [RRT](#rrt)\r\n    - [RRT\\*](#rrt-star)\r\n    - [Type 1 and Type 2 maneuvers](#maneuvers)\r\n - [Results](#results)\r\n    - [Holonomic Robot](#non-holonomic-demo)\r\n    - [Non-Holonomic Robot](#holonomic-demo)\r\n - [Source Code](#source-code)\r\n - [References](#references)\r\n \r\n## Introduction\r\nThe goal of this project is to implement sampling based motion planning \r\nalgorithms such as Rapidly-Exploring Random Tree(RRT) and its variant RRT* for a \r\nholonomic point robot and a Reeds-Shepp car like robot with \r\nnon-holonomic constraints.\r\n\r\nWhen I was implementing RRT* with non-holonomic constraints, I\r\nnoticed that we need to be able to reach a nearby point(q_near) with its \r\norientation from the new configuration(q_new). This is mostly impossible to reach\r\nby just trying the six combination of inputs that a Reeds-Shepp Car can\r\ntake. So I also implemented ***Type 1*** and ***Type 2*** maneuvers for a car like \r\nrobot to reach a desired configuration by doing combinations of these two\r\nmaneuvers.\r\n \r\n \r\n## Model Description\r\n - Robot Model &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:   Point Robot and Reeds-Shepp Car(Rigid Body)\r\n - Type        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:   Holonomic and Non-Holonomic\r\n - Workspace   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:   2-D plane with Obstacles\r\n - Collision Detection: Axis Aligned Bounding Boxes(Implemented)\r\n\r\n## Limitations\r\nFor the non-holonomic case, I'm still defining the robot as point\r\nbecause of my collision detection methods can only tell whether a point\r\nlies inside the obstacle or not. I didn't implement polygon-polygon \r\ncollision detection methods to facilitate this and also using\r\nexisting libraries for collision detection even complicates my data structures.\r\n \r\n## Collision Detection\r\n### Axis Aligned Bounding Box\r\nThe collision detection method that I implemented and used to check\r\n collision for the below path planning techniques is Axis aligned \r\n bounding boxes. Here every obstacle in the environment is bounded by a \r\n rectangle of smallest possible size and checking the robot is inside the\r\n rectangle while planning the path.\r\n \r\n## Path Planning Techniques\r\n - RRT\r\n - RRT*\r\n - Type 1 and Type 2 Maneuvers\r\n \r\n### Type 1 and Type 2 Maneuvers\r\nType 1: This maneuver is to take the robot from a configuration to another\r\nconfiguration without changing the orientation(Like parallel parking). \r\n\r\n![Type 1](images/type_1.png)\r\n\r\n\r\nType 2: This maneuver is to bring a robot from some orientation to a\r\ndesired orientation in-place(Like a three-point turn)\r\n\r\n![Type 2](images/type_2.png)\r\n\r\n***Images Source: Class Lectures***\r\n\r\nThere was a third type of movement is implemented to connect these two\r\nmaneuvers to reach the goal exactly. First, type 2 maneuver is done to \r\nchange to desired orientation and then marching forward or backward till it \r\nfinds a point that is exactly parallel to the goal configuration, then \r\ntype 1 maneuver is done to reach the goal configuration. Below GIF shows\r\ntype 1, type 2 and marching in cyan, brown and yellow colors respectively\r\nfrom the simulation.\r\n\r\n![Maneuvers](images/maneuver_gif.gif)\r\n\r\n## Results\r\n\r\n### Holonomic Robot\r\n\r\n#### RRT with 10000 random samples \r\n\r\n![RRT Holonomic](images/rrt_holo.gif)\r\n\r\n#### RRT* with 10000 random samples\r\n\r\n![RRT Star Holonomic](images/rrtstar_holo.gif)\r\n\r\n### Non-Holonomic Robot\r\n\r\n***Yellow Lines near the goal(Red Square) represents the maneuvers performed to reach the goal as desired***\r\n\r\n#### RRT with 1000 random samples \r\n\r\n![RRT Non Holonomic](images/rrt_nonholo.png)\r\n\r\n#### RRT* with 1000 random samples\r\n\r\nThe below images shows rewiring step(by doing type1 and type2 maneuvers)\r\nin multiple places.\r\n\r\n![RRT Star Non Holonomic](images/rrtstar_nonholo.png)\r\n\r\n## References\r\n\r\n 1. Karaman, Sertac, and Emilio Frazzoli. \"Incremental sampling-based algorithms for optimal motion planning.\" arXiv preprint arXiv:1005.0416 (2010).\r\n 2. Karaman, Sertac, and Emilio Frazzoli. \"Sampling-based algorithms for optimal motion planning.\" The International Journal of Robotics Research 30.7 (2011): 846-894.\r\n 3. Karaman, Sertac, and Emilio Frazzoli. \"Optimal kinodynamic motion planning using incremental sampling-based methods.\" Decision and Control (CDC), 2010 49th IEEE Conference on. IEEE, 2010.\r\n 4. Karaman, Sertac, and Emilio Frazzoli. \"Sampling-based optimal motion planning for non-holonomic dynamical systems.\" Robotics and Automation (ICRA), 2013 IEEE International Conference on. IEEE, 2013.",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}